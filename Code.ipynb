{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be0f610-bec9-47d7-a379-2456a7080f49",
   "metadata": {},
   "source": [
    "# Resume_Analyzer Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84376c00-d237-47f4-add9-411c98eb9e12",
   "metadata": {},
   "source": [
    "#### PyPDF2 for handle PDF files, extract text, and read page content.\n",
    "#### pandas for To manage and manipulate tabular data (e.g., converting results into structured formats like Excel).\n",
    "#### google-generativeai for interacting with Google's Generative AI APIs, such as Gemini for analyzing resume content and generating structured responses.\n",
    "#### tqdm for adding progress bars for visual feedback when processing multiple files.\n",
    "#### google-api-python-client for interacting with Google APIs, such as listing and downloading files from Google Drive.\n",
    "#### google-auth for handling authentication with Google APIs using a service account.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f703b7-7ae1-4a62-a4fc-6b1f5e58f77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (3.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (0.8.4)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.24.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.159.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.37.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.10.5)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from google-generativeai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.69.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.69.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (0.8.4)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.24.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.159.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.37.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.10.5)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from google-generativeai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.69.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.69.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (2.159.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (2.37.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (2.24.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (5.29.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.25.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.7.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-auth in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (2.37.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-auth) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth) (0.4.8)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (2.159.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (2.37.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (2.24.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (5.29.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.25.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.7.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (3.0.1)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (0.8.4)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.66.4)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (2.159.0)\n",
      "Requirement already satisfied: google-auth in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (2.37.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.24.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.10.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-auth) (4.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth) (0.4.8)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.69.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\gupta\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.69.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2   \n",
    "!pip install pandas\n",
    "!pip install google-generativeai\n",
    "!pip install --upgrade google-generativeai\n",
    "!pip install tqdm\n",
    "!pip install google-api-python-client\n",
    "!pip install google-auth\n",
    "!pip install google-api-python-client\n",
    "!pip install PyPDF2 pandas google-generativeai tqdm google-api-python-client google-auth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75f0112-486f-4148-9137-166c3adf810c",
   "metadata": {},
   "source": [
    "### Standard Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3713fc72-d6a7-4c5b-a04a-e670cbc48ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For file and directory operations\n",
    "import os  \n",
    "\n",
    "# For parsing and working with JSON data\n",
    "import json \n",
    "\n",
    " # For type annotations\n",
    "from typing import Dict, List, Any "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7fc5a1-2adb-4b72-addb-f709d565e5c8",
   "metadata": {},
   "source": [
    "### External Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "956c26cf-51be-4aa2-9ec5-5a0d4e080511",
   "metadata": {},
   "outputs": [],
   "source": [
    " # For reading and extracting text from PDF files\n",
    "import PyPDF2 \n",
    "\n",
    "# For handling dataframes and saving data to Excel\n",
    "import pandas as pd  \n",
    "\n",
    "# For interacting with Google's Generative AI\n",
    "import google.generativeai as genai  \n",
    "\n",
    "# For logging messages and errors during execution\n",
    "import logging  \n",
    "\n",
    "# For introducing delays in API retries\n",
    "from time import sleep  \n",
    "\n",
    "# For regular expressions to extract specific data patterns\n",
    "import re  \n",
    "\n",
    "# For concurrent processing of multiple files\n",
    "from concurrent.futures import ThreadPoolExecutor  \n",
    "\n",
    "# For displaying progress bars during long-running operations\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a1f37b-fb71-47c0-aaac-e822368059c7",
   "metadata": {},
   "source": [
    "### Google Drive API Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9822462a-fee5-4f33-85f0-0f70f410aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interacting with Google APIs (e.g., Google Drive API)\n",
    "from googleapiclient.discovery import build  \n",
    "\n",
    "# For authenticating with Google APIs using service accounts\n",
    "from google.oauth2.service_account import Credentials \n",
    "\n",
    "# For downloading files from Google Drive\n",
    "from googleapiclient.http import MediaIoBaseDownload  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dcf676-39a5-4e8a-9eb8-ae14f65b295b",
   "metadata": {},
   "source": [
    "### Initialize logging to track execution and debug issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dee1a55e-a63f-494e-ac65-0811990c7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243baa7b-6ece-42d0-9282-94ec2c880add",
   "metadata": {},
   "source": [
    "### ResumeAnalyzer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4172b26b-a822-4b44-981c-d17ed013ed1b",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "\n",
    "## 1. Initialization:\n",
    "#### Set up Generative AI.\n",
    "#### Authenticate with Google Drive API.\n",
    "\n",
    "### 2. Google Drive Integration:\n",
    "#### List and download resumes from Google Drive.\n",
    "\n",
    "### 3. Resume Analysis:\n",
    "#### Extract text from PDFs.\n",
    "#### Use Generative AI to analyze resumes.\n",
    "\n",
    "### 4. Batch Processing:\n",
    "#### Process resumes in batches for scalability and efficiency.\n",
    "\n",
    "### 5. Excel Report Generation:\n",
    "#### Save analysis results and detailed insights into an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "972a5958-a7a8-496b-99cb-69fc9758b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeAnalyzer:\n",
    "    def __init__(self, api_key: str, credentials_file: str = None, credentials_dict: Dict = None):\n",
    "        \"\"\"\n",
    "        Initialize ResumeAnalyzer with API key and either credentials file or dictionary\n",
    "        \n",
    "        Args:\n",
    "            api_key (str): Gemini API key\n",
    "            credentials_file (str, optional): Path to Google Drive service account credentials file\n",
    "            credentials_dict (Dict, optional): Google Drive service account credentials as dictionary\n",
    "\n",
    "        Workflow:\n",
    "        - Set up the Generative AI API (Gemini) using the provided API key.\n",
    "        - Initialize the Generative AI model.\n",
    "        - Configure Google Drive API authentication:\n",
    "        - If `credentials_dict` is provided, authenticate using the dictionary.\n",
    "        - If `credentials_file` is provided, authenticate using the file.\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 1: Set up the Generative AI API with the provided API key\n",
    "        self.setup_genai(api_key)\n",
    "\n",
    "        # Step 2: Initialize the Generative AI model\n",
    "        self.setup_model()\n",
    "        \n",
    "        # Step 3: Configure Google Drive API authentication\n",
    "        # Option 1: Authenticate using credentials dictionary (if provided)\n",
    "        if credentials_dict:\n",
    "            self.setup_drive_api_from_dict(credentials_dict)\n",
    "\n",
    "        # Option 2: Authenticate using credentials file (if provided)\n",
    "        elif credentials_file:\n",
    "            self.setup_drive_api_from_file(credentials_file)\n",
    "            \n",
    "\n",
    "    # Function to set up GenAI with the provided API key\n",
    "    # This function configures the GenAI service using the given API key.\n",
    "    def setup_genai(self, api_key: str) -> None:\n",
    "        genai.configure(api_key=api_key)\n",
    "\n",
    "\n",
    "    # Setup Gemini 1.5-Flash Model for Optimized Processing\n",
    "    # This method initializes the 'gemini-1.5-flash' model for faster and more efficient \n",
    "    # performance in tasks requiring generative AI.\n",
    "    def setup_model(self) -> None:\n",
    "        \"\"\"Initialize Gemini 1.5-flash model for faster processing\"\"\"\n",
    "        self.model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "    \n",
    "    # Method to Set Up Google Drive API from a Credentials Dictionary\n",
    "    def setup_drive_api_from_dict(self, credentials_dict: Dict) -> None:\n",
    "        \"\"\"Initialize Google Drive API using credentials dictionary.\n",
    "        Args:\n",
    "        credentials_dict (Dict): Dictionary containing the service account credentials.\n",
    "\n",
    "        Raises:\n",
    "        Exception: If there is an error in setting up the API with the provided credentials. \n",
    "        \"\"\"\n",
    "        try:\n",
    "             # Load credentials from the provided dictionary\n",
    "            self.creds = Credentials.from_service_account_info(\n",
    "                credentials_dict,\n",
    "                scopes=['https://www.googleapis.com/auth/drive']\n",
    "            )\n",
    "            # Initialize the Google Drive API client\n",
    "            self.drive_service = build('drive', 'v3', credentials=self.creds)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Log any errors during setup and re-raise the exception\n",
    "            logging.error(f\"Error setting up Drive API from dict: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    \n",
    "    # Method to Set Up Google Drive API from a Credentials File\n",
    "    def setup_drive_api_from_file(self, credentials_file: str) -> None:\n",
    "        \"\"\"Initialize Google Drive API using credentials file.\n",
    "        Args:\n",
    "        credentials_file (str): Path to the service account credentials file.\n",
    "\n",
    "        Raises:\n",
    "        Exception: If there is an error in setting up the API with the provided credentials file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load credentials from the provided file\n",
    "            self.creds = Credentials.from_service_account_file(\n",
    "                credentials_file,\n",
    "                scopes=['https://www.googleapis.com/auth/drive']\n",
    "            )\n",
    "            # Initialize the Google Drive API client\n",
    "            self.drive_service = build('drive', 'v3', credentials=self.creds)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Log any errors during setup and re-raise the exception\n",
    "            logging.error(f\"Error setting up Drive API from file: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "\n",
    "    # Method to List All PDF Files in a Google Drive Folder\n",
    "    def list_files_in_drive_folder(self, folder_id: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"List all PDF files in a Google Drive folder.\n",
    "         Args:\n",
    "        folder_id (str): The ID of the folder in Google Drive to search for PDF files.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries, each containing the ID and name of a PDF file.\n",
    "\n",
    "        Logs:\n",
    "        Logs the number of PDF files found in the specified folder.\n",
    "        \"\"\"\n",
    "\n",
    "        # Define query to search for PDF files in the specified folder, ensuring they are not trashed\n",
    "        query = f\"'{folder_id}' in parents and mimeType='application/pdf' and trashed = false\"\n",
    "\n",
    "        # Execute the query to list files in the folder\n",
    "        results = self.drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
    "\n",
    "        # Extract the list of files from the results\n",
    "        files = results.get('files', [])\n",
    "\n",
    "         # Log the number of files found\n",
    "        logging.info(f\"Found {len(files)} files in the folder.\")\n",
    "\n",
    "        # Return the list of found files\n",
    "        return files\n",
    "\n",
    "    \n",
    "\n",
    "    def download_file_from_drive(self, file_id: str, output_path: str) -> None:\n",
    "        \"\"\"Download a file from Google Drive.\n",
    "        \n",
    "        Args:\n",
    "        file_id (str): The ID of the file to be downloaded from Google Drive.\n",
    "        output_path (str): The local path where the downloaded file will be saved.\n",
    "    \n",
    "        Logs:\n",
    "        Logs the progress of the file download as a percentage.\"\"\"\n",
    "\n",
    "        # Create a request to fetch the file from Google Drive\n",
    "        request = self.drive_service.files().get_media(fileId=file_id)\n",
    "\n",
    "        # Open the output file in write-binary mode to store the downloaded content\n",
    "        with open(output_path, 'wb') as f:\n",
    "             # Initialize a downloader object to handle the file download\n",
    "            downloader = MediaIoBaseDownload(f, request)\n",
    "            done = False\n",
    "\n",
    "             # Loop to download the file in chunks until it's fully downloaded\n",
    "            while not done:\n",
    "                status, done = downloader.next_chunk()\n",
    "                 # Log the download progress as a percentage\n",
    "                logging.info(f\"Download progress: {int(status.progress() * 100)}%\")\n",
    "\n",
    "    \n",
    "    # Method to Download All Resumes from a Google Drive Folder to a Local Folder\n",
    "    def download_resumes_from_drive(self, folder_id: str, output_folder: str) -> List[str]:\n",
    "        \"\"\"Download all resumes from a Google Drive folder to a local folder.\n",
    "        \n",
    "        Args:\n",
    "        folder_id (str): The ID of the folder in Google Drive containing the resume files.\n",
    "        output_folder (str): The local directory where the resumes will be saved.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: A list of file paths to the downloaded resumes.\n",
    "\n",
    "        Logs:\n",
    "            Logs the progress of downloading each resume.\n",
    "        \"\"\"\n",
    "\n",
    "        # Retrieve the list of PDF files in the specified folder from Google Drive\n",
    "        files = self.list_files_in_drive_folder(folder_id)\n",
    "\n",
    "        # Initialize an empty list to store paths of downloaded files\n",
    "        downloaded_files = []\n",
    "\n",
    "        # Iterate over each file in the folder\n",
    "        for file in files:\n",
    "             # Get the file ID and name\n",
    "            file_id = file['id']\n",
    "            file_name = file['name']\n",
    "\n",
    "            # Construct the full local path to save the downloaded file\n",
    "            output_path = os.path.join(output_folder, file_name)\n",
    "            \n",
    "            # Download the file from Google Drive and save it to the local path\n",
    "            self.download_file_from_drive(file_id, output_path)\n",
    "\n",
    "            # Append the local path of the downloaded file to the list\n",
    "            downloaded_files.append(output_path)\n",
    "\n",
    "        # Return the list of downloaded file paths\n",
    "        return downloaded_files\n",
    "\n",
    "\n",
    "    # Method to Extract Text from a PDF File\n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract the text content from a PDF file.\n",
    "    \n",
    "        Args:\n",
    "        pdf_path (str): The local path to the PDF file from which text will be extracted.\n",
    "\n",
    "        Returns:\n",
    "        str: The extracted text from the PDF, with excess whitespace and non-ASCII characters removed.\n",
    "\n",
    "        Logs:\n",
    "        Logs any error that occurs during the extraction process.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            text = \"\"\n",
    "            # Open the PDF file in binary read mode\n",
    "            with open(pdf_path, \"rb\") as file:\n",
    "                reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "                # Iterate through all pages in the PDF\n",
    "                for page in reader.pages:\n",
    "                    # Extract text from each page\n",
    "                    page_text = page.extract_text()\n",
    "\n",
    "                    # Clean up the extracted text: remove extra whitespace and non-ASCII characters\n",
    "                    page_text = re.sub(r'\\s+', ' ', page_text)\n",
    "                    page_text = re.sub(r'[^\\x00-\\x7F]+', '', page_text)\n",
    "\n",
    "                    # Append the cleaned text from each page to the result\n",
    "                    text += page_text + \"\\n\"\n",
    "\n",
    "            # Return the cleaned text from the entire PDF\n",
    "            return text.strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            # Log any error encountered during text extraction\n",
    "            logging.error(f\"Error extracting text from PDF {pdf_path}: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    \n",
    "    # Method to Clean and Extract JSON Content from a Response String\n",
    "    def clean_json_response(self, response_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Clean and extract JSON content from a given response string.\n",
    "    \n",
    "        Args:\n",
    "            response_text (str): The response text containing the JSON data to be cleaned and extracted.\n",
    "\n",
    "        Returns:\n",
    "            str: A cleaned version of the extracted JSON string, with unnecessary characters removed.\n",
    "    \n",
    "        Logs:\n",
    "            Logs any errors encountered during the extraction and cleaning process.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Use regular expression to find the JSON content in the response\n",
    "            json_content = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "\n",
    "            # If JSON content is found, clean and format it\n",
    "            if json_content:\n",
    "                json_str = json_content.group()\n",
    "\n",
    "                 # Remove any ` ```json ` and ` ``` ` markers\n",
    "                json_str = re.sub(r'```json|```', '', json_str)\n",
    "\n",
    "                # Replace multiple spaces with a single space to clean up the formatting\n",
    "                json_str = re.sub(r'\\s+', ' ', json_str)\n",
    "\n",
    "                # Return the cleaned JSON string\n",
    "                return json_str.strip()\n",
    "            return \"\"    # Return the cleaned JSON string\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Log any error encountered during the cleaning process\n",
    "            logging.error(f\"Error cleaning JSON response: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    def analyze_resume(self, text: str) -> Dict[str, Any]:\n",
    "        # Few-shot examples for better context\n",
    "        few_shot_examples = \"\"\"\n",
    "        Example 1:\n",
    "        Input: \"John Doe, BS Computer Science, Stanford University, 3.8 GPA...\"\n",
    "        Output: {\"name\": \"John Doe\", \"university\": \"Stanford University\", \"course\": \"BS Computer Science\"...}\n",
    "        \n",
    "        Example 2:\n",
    "        Input: \"Jane Smith, Machine Learning Engineer with 3 years experience...\"\n",
    "        Output: {\"name\": \"Jane Smith\", \"ai_ml_score\": 3, \"gen_ai_score\": 2...}\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        {few_shot_examples}\n",
    "        \n",
    "        Analyze this resume carefully and extract information according to these specific rules:\n",
    "\n",
    "        Scoring Rules:\n",
    "        1. Gen AI Experience Score (1-3):\n",
    "           - Score 1: Basic exposure or theoretical knowledge\n",
    "           - Score 2: Hands-on projects or internships with Gen AI\n",
    "           - Score 3: Advanced work (e.g., Agentic RAG, Evals, LLM fine-tuning)\n",
    "           \n",
    "        2. AI/ML Experience Score (1-3):\n",
    "           - Score 1: Basic ML/AI knowledge or coursework\n",
    "           - Score 2: Hands-on ML/AI projects or internships\n",
    "           - Score 3: Advanced ML/AI work (e.g., research, complex implementations)\n",
    "\n",
    "        Required JSON structure:\n",
    "        {{\n",
    "            \"name\": \"full name\",\n",
    "            \"contact_details\": \"all contact information as shown\",\n",
    "            \"university\": \"university name\",\n",
    "            \"year_of_study\": \"current year or graduation year\",\n",
    "            \"course\": \"degree name\",\n",
    "            \"discipline\": \"field of study\",\n",
    "            \"cgpa_percentage\": \"exact CGPA or percentage\",\n",
    "            \"key_skills\": [\"all technical and relevant skills\"],\n",
    "            \"gen_ai_score\": \"1-3 based on rules above\",\n",
    "            \"ai_ml_score\": \"1-3 based on rules above\",\n",
    "            \"supporting_info\": {{\n",
    "                \"certifications\": [\"list of certifications\"],\n",
    "                \"internships\": [\"list of internships with details\"],\n",
    "                \"projects\": [\n",
    "                    {{\n",
    "                        \"name\": \"project name\",\n",
    "                        \"description\": \"brief description\",\n",
    "                        \"technologies\": [\"technologies used\"]\n",
    "                    }}\n",
    "                ]\n",
    "            }},\n",
    "            \"additional_insights\": {{\n",
    "                \"career_potential\": \"brief assessment of career trajectory\",\n",
    "                \"technical_strength\": \"evaluation of technical capabilities\",\n",
    "                \"experience_level\": \"overall experience assessment\"\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        Resume text to analyze:\n",
    "        {text}\n",
    "        \"\"\"\n",
    "\n",
    "        # Method to Generate and Analyze Content from a Model with Retry Logic\n",
    "        try:\n",
    "            max_retries = 3   # Set the maximum number of retry attempts\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    # Attempt to generate content using the model with the given prompt\n",
    "                    response = self.model.generate_content(prompt)\n",
    "\n",
    "                    # Check if the response is empty, raise an error if so\n",
    "                    if not response.text:\n",
    "                        raise ValueError(\"Empty response received\")\n",
    "\n",
    "                    # Clean and extract JSON content from the response text\n",
    "                    json_str = self.clean_json_response(response.text)\n",
    "\n",
    "                    # Check if the cleaned response is valid, raise an error if not\n",
    "                    if not json_str:\n",
    "                        raise ValueError(\"No valid JSON found in response\")\n",
    "\n",
    "                    # Parse the cleaned JSON string into a Python dictionary\n",
    "                    data = json.loads(json_str)\n",
    "                    \n",
    "                    # Define required fields that must be present in the parsed data\n",
    "                    required_fields = [\n",
    "                        \"name\", \"contact_details\", \"university\", \"year_of_study\",\n",
    "                        \"course\", \"discipline\", \"cgpa_percentage\", \"key_skills\",\n",
    "                        \"gen_ai_score\", \"ai_ml_score\"\n",
    "                    ]\n",
    "\n",
    "                    # Check for missing required fields\n",
    "                    missing_fields = [field for field in required_fields if field not in data]\n",
    "\n",
    "                     # Raise an error if any required fields are missing\n",
    "                    if missing_fields:\n",
    "                        raise ValueError(f\"Missing required fields: {missing_fields}\")\n",
    "\n",
    "                    # Return the parsed data if everything is valid\n",
    "                    return data\n",
    "                    \n",
    "                except json.JSONDecodeError as je:\n",
    "                    # Handle JSON parsing errors: log a warning and retry if attempts remain\n",
    "                    logging.warning(f\"JSON parse error on attempt {attempt + 1}: {str(je)}\")\n",
    "                    if attempt == max_retries - 1:\n",
    "                        raise   # Raise the exception if it is the final retry\n",
    "                    sleep(1)    # Shorter sleep between retries for faster feedback\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # Handle other exceptions: log and retry if attempts remain\n",
    "                    if attempt == max_retries - 1:\n",
    "                        raise     # Raise the exception if it is the final retry\n",
    "                    sleep(1)      # Short sleep for retry logic\n",
    "                    \n",
    "        except Exception as e:\n",
    "            # Log any error that occurs during the overall process and return an empty dictionary\n",
    "            logging.error(f\"Error analyzing resume: {str(e)}\")\n",
    "            return {}\n",
    "            \n",
    "            \n",
    "    # Method to Process a Batch of Resumes Concurrently\n",
    "    def process_resume_batch(self, pdf_paths: List[str]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Process a batch of resumes concurrently\n",
    "        Args:\n",
    "            pdf_paths (List[str]): A list of file paths to the PDF resumes to be processed.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: A list of dictionaries containing the processed data from each resume.\n",
    "    \n",
    "        Logs:\n",
    "            Logs errors encountered while processing individual resumes.\n",
    "        \"\"\"\n",
    "        # List to store the results of successfully processed resumes\n",
    "        results =[]\n",
    "\n",
    "        # Use a ThreadPoolExecutor to process resumes concurrently with a maximum of 5 workers\n",
    "        with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            # Create a mapping of future objects to their respective PDF paths\n",
    "            future_to_path = {\n",
    "                executor.submit(self.process_single_resume, path): path \n",
    "                for path in pdf_paths\n",
    "            }\n",
    "            # Iterate over each future in the thread pool and track progress with tqdm\n",
    "            for future in tqdm(future_to_path, desc=\"Processing resumes\"):\n",
    "                try:\n",
    "                    # Retrieve the result from the future (blocks until completion)\n",
    "                    result = future.result()\n",
    "                    \n",
    "                    # If the result is valid (non-empty), append it to the results list\n",
    "                    if result:\n",
    "                        results.append(result)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    # Log any error encountered while processing a particular resume\n",
    "                    logging.error(f\"Error processing {future_to_path[future]}: {str(e)}\")\n",
    "\n",
    "        # Return the list of results after processing all resumes\n",
    "        return results\n",
    "\n",
    "    \n",
    "    # Method to Process a Single Resume\n",
    "    def process_single_resume(self, pdf_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process a single resume\n",
    "        Args:\n",
    "            pdf_path (str): The file path to the PDF resume to be processed.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: A dictionary containing the analysis results or an empty dictionary if processing fails.\n",
    "\n",
    "        Logs:Logs any errors encountered during the resume processing.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Extract text from the given PDF file\n",
    "            resume_text = self.extract_text_from_pdf(pdf_path)\n",
    "\n",
    "            # If no text was extracted from the PDF, return an empty dictionary\n",
    "            if not resume_text:\n",
    "                return {}\n",
    "\n",
    "            # Analyze the extracted resume text and obtain the results\n",
    "            result = self.analyze_resume(resume_text)\n",
    "\n",
    "            # If analysis returns valid data, add the source file name to the result\n",
    "            if result:\n",
    "                result['source_file'] = os.path.basename(pdf_path)\n",
    "                \n",
    "            # Return the analysis result\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Log any error encountered during the resume processing\n",
    "            logging.error(f\"Error processing {pdf_path}: {str(e)}\")\n",
    "\n",
    "            # Return an empty dictionary in case of an error\n",
    "            return {}\n",
    "\n",
    "\n",
    "    # Method to Create Detailed Sheets in an Excel File\n",
    "    def create_detailed_sheets(self, writer: pd.ExcelWriter, results: List[Dict[str, Any]]) -> None:\n",
    "        \"\"\"Create additional sheets with detailed information\\\n",
    "        Args:\n",
    "            writer (pd.ExcelWriter): The Excel writer object to write the data to the file.\n",
    "            results (List[Dict[str, Any]]): A list of dictionaries containing processed resume data.\n",
    "    \n",
    "        Logs:\n",
    "            The method processes and writes detailed data to separate sheets for projects and skills analysis.\n",
    "        \"\"\"\n",
    "        # Projects sheet: Extract and collect project data from the results\n",
    "        projects_data = []\n",
    "        for result in results:\n",
    "            # Check if 'supporting_info' and 'projects' are present in the result\n",
    "            if 'supporting_info' in result and 'projects' in result['supporting_info']:\n",
    "                for project in result['supporting_info']['projects']:\n",
    "                    # Add the candidate's name to each project entry\n",
    "                    project['candidate_name'] = result['name']\n",
    "                    projects_data.append(project)\n",
    "\n",
    "        # If there is project data, create a DataFrame and write it to the 'Projects' sheet\n",
    "        if projects_data:\n",
    "            pd.DataFrame(projects_data).to_excel(writer, sheet_name='Projects', index=False)\n",
    "\n",
    "        # Skills Analysis sheet: Extract and collect skills-related data\n",
    "        skills_data = []\n",
    "        for result in results:\n",
    "            # Check if 'key_skills' are present in the result\n",
    "            if 'key_skills' in result:\n",
    "                skills_data.append({\n",
    "                    'name': result['name'],\n",
    "                    'skills': ', '.join(result['key_skills']),\n",
    "                    'ai_ml_score': result['ai_ml_score'],\n",
    "                    'gen_ai_score': result['gen_ai_score']\n",
    "                })\n",
    "\n",
    "        # If there is skills data, create a DataFrame and write it to the 'Skills Analysis' sheet\n",
    "        if skills_data:\n",
    "            pd.DataFrame(skills_data).to_excel(writer, sheet_name='Skills Analysis', index=False)\n",
    "\n",
    "    def process_resumes(self, pdf_folder: str, output_excel: str) -> None:\n",
    "        \"\"\"Process all resumes in the folder with batch processing\"\"\"\n",
    "        # Step 1: Validate the PDF folder path\n",
    "        if not os.path.exists(pdf_folder):\n",
    "            raise ValueError(f\"Folder not found: {pdf_folder}\")\n",
    "            \n",
    "        ## Step 2: Get all PDF files from the specified folder\n",
    "        pdf_files = [\n",
    "            os.path.join(pdf_folder, f) \n",
    "            for f in os.listdir(pdf_folder) \n",
    "            if f.endswith('.pdf')\n",
    "        ]\n",
    "        \n",
    "        # Step 3: Process the files in batches for optimal performance\n",
    "        batch_size = 10\n",
    "        all_results = []\n",
    "        failed_files = []\n",
    "        \n",
    "        # Iterate through the PDF files in batches\n",
    "        for i in range(0, len(pdf_files), batch_size):\n",
    "            batch = pdf_files[i:i + batch_size]\n",
    "            results = self.process_resume_batch(batch)\n",
    "            \n",
    "            # Step 4: Filter out and collect successful results\n",
    "            all_results.extend([r for r in results if r])\n",
    "            \n",
    "            # Track failed files for reporting\n",
    "            processed_files = {r.get('source_file') for r in results if r}\n",
    "            failed_files.extend([\n",
    "                (os.path.basename(f), \"Processing failed\")\n",
    "                for f in batch\n",
    "                if os.path.basename(f) not in processed_files\n",
    "            ])\n",
    "\n",
    "        # Step 5: Check if any files were successfully processed\n",
    "        if not all_results:\n",
    "            logging.warning(\"No resume data was successfully processed\")\n",
    "            return\n",
    "\n",
    "        # Step 6: Create a DataFrame from the processed results\n",
    "        try:\n",
    "            # Create DataFrame with organized columns\n",
    "            df = pd.json_normalize(\n",
    "                all_results,\n",
    "                sep='_',\n",
    "                record_path=None,\n",
    "                meta=[\n",
    "                    'source_file', 'name', 'contact_details', 'university',\n",
    "                    'year_of_study', 'course', 'discipline', 'cgpa_percentage',\n",
    "                    'gen_ai_score', 'ai_ml_score'\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            ## Step 7: Format and save the results to an Excel file\n",
    "            with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:\n",
    "                # Main analysis sheet\n",
    "                df.to_excel(writer, sheet_name='Resume Analysis', index=False)\n",
    "                \n",
    "                # Additional sheets for detailed information if available\n",
    "                if all_results:\n",
    "                    self.create_detailed_sheets(writer, all_results)\n",
    "                \n",
    "                # # Step 8: Add a sheet for the failed files\n",
    "                if failed_files:\n",
    "                    pd.DataFrame(failed_files, columns=['Filename', 'Error']).to_excel(\n",
    "                        writer, sheet_name='Failed Files', index=False\n",
    "                    )\n",
    "\n",
    "            # Log completion information\n",
    "            logging.info(f\"Processing complete. Output saved to {output_excel}\")\n",
    "            logging.info(f\"Successfully processed: {len(all_results)} resumes\")\n",
    "            logging.info(f\"Failed to process: {len(failed_files)} resumes\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Handle any errors during Excel saving\n",
    "            logging.error(f\"Error saving to Excel: {str(e)}\")\n",
    "\n",
    "    def process_resumes_from_drive(self, folder_id: str, output_excel: str, local_temp_folder: str) -> None:\n",
    "        \"\"\"Download resumes from Google Drive, process them, and save results.\"\"\"\n",
    "\n",
    "        # Step 1: Ensure local temporary folder exists\n",
    "        if not os.path.exists(local_temp_folder):\n",
    "            os.makedirs(local_temp_folder)\n",
    "\n",
    "        # Step 2: Download resumes from the specified Google Drive folder\n",
    "        logging.info(\"Downloading resumes from Google Drive...\")\n",
    "        downloaded_files = self.download_resumes_from_drive(folder_id, local_temp_folder)\n",
    "        \n",
    "        # Step 3: Process the downloaded resumes locally\n",
    "        logging.info(\"Processing downloaded resumes...\")\n",
    "        self.process_resumes(local_temp_folder, output_excel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630cee94-d67b-4efb-a84e-4f53db608a77",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "698ab09a-b967-428e-9802-d73c2845ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process resumes from Google Drive using the ResumeAnalyzer class.\n",
    "    \"\"\"\n",
    "    # Step 1: Define API Key for Gemini (Google Generative AI)\n",
    "    api_key = \"AIzaSyAwcPMYXwd_ytgkZ0Od002VXcxNED7mss0\"  # Replace with your Gemini API key\n",
    "\n",
    "    # Step 2: Define Google Drive Service Account Credentials\n",
    "    # These credentials are required to authenticate with the Google Drive API.\n",
    "    credentials_dict = {\n",
    "        \"type\": \"service_account\",\n",
    "        \"project_id\": \"resume-analyzer-448509\",\n",
    "        \"private_key_id\": \"177d2fa6bd581d378501302bfea73d83120aa3f2\",\n",
    "        \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQCmyXkcdxBmxm4s\\nzqV/M+t/ie+Q8AyzISlLjItEMwWOL5fyoT2oztXh85hyXRQ5VgjTw8ZbEm9+kM4K\\nJTOVYo8KwX0m1+/9hcc2NBdGtNWgmwVjelBlMNLAKtpfV3W+wtOXPVdwIIzVh4ZW\\nC/tegE09WZamV2npzIOlamdmDrrVOTa8K2tmd60hLx4Zm6wh943GDntjEEyKPnXt\\nTD99231Y9e9/0ENUMZImALDHEk+PZUasBB2zCX4/hM95dnwjcftjsnKmlqdqbJ4T\\n+urPX0NcD796BnF+/CzCEvxJE9QxM5B5xo+MijnSHmSZh5DADNVFjG61i5tmEu55\\nkBEzcUBTAgMBAAECggEANyRqRcZ5pjkZqPfDUKx2Qkr06RrsX/bpQ8CaNLiXsBw9\\nJOs5SwvjO9qBPuJWMuSmc3kJJggQ06wFauZEyTF2MGyrN4HyJwQpSlrrjSVxcbF/\\nFRYV6Xa8XutsGlR8qc6ZDSorM/eXCGvPtrgsaeCKaOurOqCw9Cr5JWHqAJyDGcZQ\\n1qbDejjJYdT9Clnhgo3VO0wLGL16kIXoeVhFEFSz1bfVeAN13SsXoZwNtWIALHed\\nYbRs/m/h7rH1SjFXReqstDuNycdg3P1qA3zzEcvXnemDIS9XoLLVTQ8+EHEXX9OK\\nW4Mic9oik76vEia0gqy/r8koMKX0foUpBtYxg86soQKBgQDlgAyhPDlKytSiogGn\\nr3EoTI2gal8sEJT3vJ6YqH191dZlbIJDqw/Izm5dUblK+OfJgRT+/aqOCfBuWixo\\nfolXZIEVf6haamoG5OxBMm6BPtLVZKxTqiUGm06fbb/VgDn+Ne93qhAfh3Saud/d\\nA9cgKznrSh5oRDp5rBcB7L5mMwKBgQC6C6R01neAjvpgEHnXTycnIbEIMJNch8+P\\niA8FBVmyDG2s2Tquxi3zy/DIWaOlcU4hbUn69sqlDzxMnBbD0EUpcpSOTd1wb0AU\\n0awpKgSGkeKeSErcGTtK2ZFZrSXJ80+R7v3LJBWQe9V5+KJuQ8t8qBXqNLc/hTyf\\naET+NyRdYQKBgFsWHm0j9O09YXWG7Tc7h6Lh91gSv+FCV42X3C5kuSHnbCdnELCA\\nxUwCuoTpOayK65vrUoT98uJbCYUS3ws+JY59AkqhFxWDpL9FvosF1BwR7iXpxgeS\\nwQ1FOMhIC9pWAS5nA7sv0SRiY6JBYZtbudc3sM405aqmYbsG1T7bUppHAoGAfLpL\\nci1KhrzUbMz+8nNVe22iAyyVzuYaKE7+Ss5weObOLKCiMAQbUKQ8dAVsqgERcWWU\\nwJTt/MT/FxlaRcL+azAvGkxnlfZvzsVXF23dBN8PQDCVR4P+9UpxoN5tRDxD70F7\\nktJJRslOsGwZcbUv2g3SS2c2J3bK0tAT2R7c2WECgYEAuNBKriXImge1Hn+PowWQ\\nR998RVjwnmC4LTMXNsA2idS32rHKwks1xffAcex/MuQkZEqtfls4KWtm/nzstgAG\\ndY3scxo0ozYrj/oEvBE5DE6XOo8o29uN0KIyGMqRjZxo+2TASKi/aAgrfztlZW2v\\nDcYyCh3/+vGea7+GXAkuRcA=\\n-----END PRIVATE KEY-----\\n\",\n",
    "        \"client_email\": \"resume-analyzer-service-449@resume-analyzer-448509.iam.gserviceaccount.com\",\n",
    "        \"client_id\": \"101646634736421126921\",\n",
    "        \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "        \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "        \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "        \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/resume-analyzer-service-449%40resume-analyzer-448509.iam.gserviceaccount.com\",\n",
    "        \"universe_domain\": \"googleapis.com\"\n",
    "    }\n",
    "\n",
    "    # Step 3: Define Google Drive Folder ID and Local Temporary Folder\n",
    "    drive_folder_id = \"1k8DS8dmm3fmUuwRIxv-g16SSI4GtB69P\"  # Google drive folder ID\n",
    "    local_temp_folder = \"local_resumes_folder\"  # Temporary folder for downloaded files \n",
    "\n",
    "    # Step 4: Specify the Output Excel File Name\n",
    "    output_excel = \"Resume_Analysis_Output.xlsx\"\n",
    "\n",
    "    # Step 5: Initialize ResumeAnalyzer\n",
    "    # This sets up the Generative AI and Google Drive integrations\n",
    "    analyzer = ResumeAnalyzer(api_key, credentials_dict=credentials_dict)\n",
    "    \n",
    "    # Step 6: Process Resumes from Google Drive\n",
    "    # Downloads resumes from the Drive folder, processes them, and saves the analysis to an Excel file\n",
    "    analyzer.process_resumes_from_drive(drive_folder_id, output_excel, local_temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fdce75-f27c-4aae-a310-0fb8da213827",
   "metadata": {},
   "source": [
    "### Execute the Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4a4228f-e5d7-4a3c-af9b-287d0aaf5863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 20:59:00,606 - INFO - file_cache is only supported with oauth2client<4.0.0\n",
      "2025-01-21 20:59:00,669 - INFO - Downloading resumes from Google Drive...\n",
      "2025-01-21 20:59:02,305 - INFO - Found 15 files in the folder.\n",
      "2025-01-21 20:59:04,002 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:06,221 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:07,780 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:09,357 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:11,135 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:12,564 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:14,670 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:16,006 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:17,596 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:19,216 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:20,409 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:21,857 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:23,430 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:35,846 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:37,428 - INFO - Download progress: 100%\n",
      "2025-01-21 20:59:37,429 - INFO - Processing downloaded resumes...\n",
      "Processing resumes: 100%|| 10/10 [00:18<00:00,  1.81s/it]\n",
      "Processing resumes: 100%|| 5/5 [00:09<00:00,  1.97s/it]\n",
      "2025-01-21 21:00:07,229 - INFO - Processing complete. Output saved to Resume_Analysis_Output.xlsx\n",
      "2025-01-21 21:00:07,229 - INFO - Successfully processed: 15 resumes\n",
      "2025-01-21 21:00:07,229 - INFO - Failed to process: 0 resumes\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81df1da-1595-470f-9283-8de8ff0de99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
